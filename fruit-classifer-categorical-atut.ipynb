{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training our Fruit Classifer","metadata":{"id":"jg4sc8GDRYOX"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:01:43.954494Z","iopub.execute_input":"2022-08-31T15:01:43.956924Z","iopub.status.idle":"2022-08-31T15:01:43.987095Z","shell.execute_reply.started":"2022-08-31T15:01:43.956813Z","shell.execute_reply":"2022-08-31T15:01:43.986304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf; print(tf.__version__)\nimport keras; print(keras.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:01:49.023212Z","iopub.execute_input":"2022-08-31T15:01:49.023621Z","iopub.status.idle":"2022-08-31T15:01:56.061293Z","shell.execute_reply.started":"2022-08-31T15:01:49.023589Z","shell.execute_reply":"2022-08-31T15:01:56.059964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nimport os\n\nnum_classes = 131\nimg_rows, img_cols = 64, 64\nbatch_size = 128\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_data_dir = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training/'\nvalidation_data_dir = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test/'\n\n# Let's use some data augmentaiton \ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=30,\n      width_shift_range=0.3,\n      height_shift_range=0.3,\n      horizontal_flip=True,\n      fill_mode='nearest')\n \nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n \n#Training Data    \ntrain_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_rows, img_cols),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=True)\n#Validation Data\nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_rows, img_cols),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False)\n","metadata":{"id":"uW8dKXPhRYOb","outputId":"b05124e0-66a5-4d17-ac8b-87df6de958ef","execution":{"iopub.status.busy":"2022-08-31T15:01:59.124983Z","iopub.execute_input":"2022-08-31T15:01:59.125968Z","iopub.status.idle":"2022-08-31T15:02:04.370787Z","shell.execute_reply.started":"2022-08-31T15:01:59.125926Z","shell.execute_reply":"2022-08-31T15:02:04.369715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's define our model","metadata":{"id":"gpmvr1dNRYOd"}},{"cell_type":"code","source":"#model = Sequential()\n\n# Padding = 'same'  results in padding the input such that\n# the output has the same length as the original input\n#model.add(Conv2D(256, (3, 3), padding='same',input_shape= (img_rows, img_cols, 3)))\n#model.add(Activation('relu'))\n#model.add(Conv2D(128, (3, 3)))\n#model.add(Activation('relu'))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n\n#model.add(Conv2D(64, (3, 3), padding='same'))\n#model.add(Activation('relu'))\n#model.add(Conv2D(64, (3, 3)))\n#model.add(Activation('relu'))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n\n#model.add(Flatten())\n#model.add(Dense(128))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.5))\n#model.add(Dense(num_classes))\n#model.add(Activation('softmax'))\n\n# initiate RMSprop optimizer and configure some parameters\n#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n#print(model.summary())\n\n\nmodel=Sequential()\n\n#Convolution blocks\nmodel.add(Conv2D(128, kernel_size = (3,3), padding='same',input_shape=(img_rows,img_cols,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2)) \n\nmodel.add(Conv2D(64, kernel_size = (3,3), padding='same',activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2)) \n\n#model.add(Conv2D(256, kernel_size = (3,3), padding='same',activation='relu'))\n#model.add(MaxPooling2D(pool_size=2)) \n\n#Classification layers\nmodel.add(Flatten())\n\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.2))\n\n\n\nmodel.add(Dense(num_classes,activation='softmax'))\n\n\nmodel.summary()","metadata":{"id":"PHE9KJ4ZRYOd","execution":{"iopub.status.busy":"2022-08-31T15:02:07.525277Z","iopub.execute_input":"2022-08-31T15:02:07.526259Z","iopub.status.idle":"2022-08-31T15:02:07.736280Z","shell.execute_reply.started":"2022-08-31T15:02:07.526179Z","shell.execute_reply":"2022-08-31T15:02:07.735095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We use a very small learning rate \nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = 'RMSprop',\n              metrics = ['accuracy'])\n\nnb_train_samples = 67692\nnb_validation_samples = 22688\nepochs = 50","metadata":{"id":"S79gNvEdRYOe","outputId":"235a9800-5e41-4efb-d70d-0c3a18a3ea4d","execution":{"iopub.status.busy":"2022-08-31T15:02:12.646470Z","iopub.execute_input":"2022-08-31T15:02:12.646924Z","iopub.status.idle":"2022-08-31T15:02:12.832318Z","shell.execute_reply.started":"2022-08-31T15:02:12.646881Z","shell.execute_reply":"2022-08-31T15:02:12.831214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n    train_generator,\n    steps_per_epoch = nb_train_samples // batch_size,\n    epochs = epochs,\n    validation_data = validation_generator,\n    validation_steps = nb_validation_samples // batch_size)\n\nmodel.save('fruit_classifier1.h5')\n\nimport pickle\npickle_out = open('fruit_classifier2.pkl','wb')\npickle.dump(history.history,pickle_out)\npickle_out.close()\n\npickle_in = open('fruit_classifier2.pkl','rb')\nhistory=pickle.load(pickle_in)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T15:02:15.624893Z","iopub.execute_input":"2022-08-31T15:02:15.625362Z","iopub.status.idle":"2022-08-31T18:18:44.743926Z","shell.execute_reply.started":"2022-08-31T15:02:15.625325Z","shell.execute_reply":"2022-08-31T18:18:44.741272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\npickle_in = open('fruit_classifier2.pkl','rb')\nhistory=pickle.load(pickle_in)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T02:20:23.201935Z","iopub.execute_input":"2022-08-31T02:20:23.202428Z","iopub.status.idle":"2022-08-31T02:20:23.292443Z","shell.execute_reply.started":"2022-08-31T02:20:23.202328Z","shell.execute_reply":"2022-08-31T02:20:23.291116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Displaying our Confusion Matrix","metadata":{"id":"9SSxO-B0RYOf"}},{"cell_type":"code","source":"class_labels = validation_generator.class_indices\nclass_labels = {v: k for k, v in class_labels.items()}\nclasses = list(class_labels.values())\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n#Confution Matrix and Classification Report\nY_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n\nprint(validation_generator.classes)","metadata":{"id":"YOTQS_wjRYOf","outputId":"033418d2-45c0-4294-f39e-ad6a57c806dd","execution":{"iopub.status.busy":"2022-08-25T06:21:17.939843Z","iopub.execute_input":"2022-08-25T06:21:17.940694Z","iopub.status.idle":"2022-08-25T06:21:54.101778Z","shell.execute_reply.started":"2022-08-25T06:21:17.940652Z","shell.execute_reply":"2022-08-25T06:21:54.100884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classes)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T06:22:20.193599Z","iopub.execute_input":"2022-08-25T06:22:20.194043Z","iopub.status.idle":"2022-08-25T06:22:20.199635Z","shell.execute_reply.started":"2022-08-25T06:22:20.194007Z","shell.execute_reply":"2022-08-25T06:22:20.198911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing our fruit classifier","metadata":{"id":"UdCBE7lURYOg"}},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('fruit_classifier1.h5')\n\n\ndef print_result(result):\n    i,j = np.unravel_index(result.argmax(), result.shape)\n    print(f'Prediction: {classes[j]} | Probability: {result[i,j]} | {i},{j}')   \n\ndef predict_image_model(image_path : str) -> np.ndarray:\n    img_size = (img_rows, img_cols)\n    # load imamge into a 4D Tensor, convert it to a numpy array and expand to 4 dim\n    img1 = image.load_img(image_path, target_size = img_size)\n    image_tensor = image.img_to_array(img1)\n    #print(image_tensor.shape)\n    image_tensor = image_tensor/255\n    image_tensor = np.expand_dims(image_tensor, axis=0)\n    #print(img.shape)\n    result = model.predict(image_tensor)\n    return result\n\nfrom keras.preprocessing import image\ntest_img_path_1  = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test/Cherry Wax Red/191_100.jpg'\ntest_img_path_2 = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test/Watermelon/r_95_100.jpg'\ntest_img_path_3  = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test/Tomato not Ripened/r_297_100.jpg'\ntest_img_path_4 = '/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Test/apple_crimson_snow_1/r1_59.jpg'\n#result\nresult = predict_image_model(test_img_path_1)#Cherry Wax Red\nprint_result(result)\nresult = predict_image_model(test_img_path_2)#Watermelon\nprint_result(result)\nresult = predict_image_model(test_img_path_3)#Tomato not Ripened\nprint_result(result)\nresult = predict_image_model(test_img_path_4)#apple_crimson_snow_1\nprint_result(result)\n\n\n\n \n\n","metadata":{"id":"wpla-EbIRYOg","execution":{"iopub.status.busy":"2022-08-25T06:22:38.099140Z","iopub.execute_input":"2022-08-25T06:22:38.099552Z","iopub.status.idle":"2022-08-25T06:22:38.539296Z","shell.execute_reply.started":"2022-08-25T06:22:38.099522Z","shell.execute_reply":"2022-08-25T06:22:38.538305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_history = history\ndata_history['epochs']= [i for i in range(1,epochs+1)]\ndata_history","metadata":{"execution":{"iopub.status.busy":"2022-08-25T06:23:51.801780Z","iopub.execute_input":"2022-08-25T06:23:51.802269Z","iopub.status.idle":"2022-08-25T06:23:51.809461Z","shell.execute_reply.started":"2022-08-25T06:23:51.802234Z","shell.execute_reply":"2022-08-25T06:23:51.808659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n_epochs = data_history['epochs']\n_loss = data_history['loss']\n_accuracy = data_history['accuracy']\n_val_accuracy = data_history['val_accuracy']\n_val_loss = data_history['val_loss']\n\nplt.plot(_epochs,_val_accuracy)\n","metadata":{"id":"PMdBjvxsRYOh","execution":{"iopub.status.busy":"2022-08-25T06:23:55.148749Z","iopub.execute_input":"2022-08-25T06:23:55.149802Z","iopub.status.idle":"2022-08-25T06:23:55.332900Z","shell.execute_reply.started":"2022-08-25T06:23:55.149762Z","shell.execute_reply":"2022-08-25T06:23:55.331837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(_epochs,_accuracy)","metadata":{"id":"dh9n6Io4RYOi","execution":{"iopub.status.busy":"2022-08-25T06:23:57.542723Z","iopub.execute_input":"2022-08-25T06:23:57.543606Z","iopub.status.idle":"2022-08-25T06:23:57.736632Z","shell.execute_reply.started":"2022-08-25T06:23:57.543570Z","shell.execute_reply":"2022-08-25T06:23:57.735573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"YjwcIUfuRYOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"11KfCliPRYOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"yZysBgeCRYOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"VPf-9DtzRYOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"nApvwqUqRYOj"},"execution_count":null,"outputs":[]}]}